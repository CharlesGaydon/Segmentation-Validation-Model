# Optimization and evaluation of building validation decision thresholds

## Motivations

As described in section [`Building Validation`](background/production_process.md) of the production process, the decision to validate or not a group of candidate buildings is based on several decision thresholds. Those thresholds represents different levels of confidence, for different sources of data. 

They may depend the AI model which produces the probabilities as well as on the rule-based classification from which the clusters of candidates are derived. They are highly coupled. For instance, if a lower probability is required at the point level to be confirmed as a building (threshold `C1`), we might require a higher percentage of confirmed points in a cluster of candidates (thresholds `C2`) to validate it. There must therefore be optimized jointly. 

These thresholds define how much we automate decisions, but also the quantity of errors we may introduce: there is a balance to be found between `recall` (proportion of buildings group that were confirmed), `precision` (proportion of buildings among confirmed groups), and `automation` (proportion of groups for which a decision was made i.e. that are not flagged as "unsure"). 

## Strategy

We approach the choice of decisions thresholds as a constrained multi-objectives hyperparameters optimization.
We use the [NSGA-II](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.NSGAIISampler.html#optuna.samplers.NSGAIISampler) algorithm from the optuna optimization library.
The constraints are defined empirically: recall>=98% and precision>=98%.
The genetic algorithms search two maximize the three objectives, but focuses the search to solutions that meets these criteria. 
After a chosen number of generations, the genetic algorithms outputs the [Pareto front](https://en.wikipedia.org/wiki/Pareto_front) i.e. the set of Pareto efficient solutions for which no objective criterion could be increased without another one being reduced.
Among Pareto-efficient solutions compliant with the constraint, the final solution is the set of thresholds that maximizes the production of precision, recall, and automation.


## Running the optimization

### Requirements

To optimize the decision thresholds you must be able to evaluate the level of automation that can be reached on data that matches production data. As a result, you need to have _corrected_ data i.e. data of which a rule-based classification was corrected and for which you keep track of the corrections that were made. For building validation, the classification must have codes to distinguish false positive, false negative, and true positive. Theses codes may be configured with parameter `buildings_correction_labels` under configuration group `bulding_validation.optimization`.

Furthermore, the point cloud data must include predictions from the deep learning model trained to detect buildings. This consists in two channels : a `building` channel with predicted probabilities and an `entropy` channel.

A large validation dataset might help having a better sense of the app performances. We used 15km² of corrected data to optimize thresholds, but a larger set might provide more diversity. This being said, performance on an unseen test set was almost equal to performance on the validation set, which indicates a robust evaluation for such volume of data. 

## Implementation details

In lidar-prod, each task is implemented by a dedicated python class. Building Validation is implemented via a `BuildingValidator` class. We make sure that all parameters used for optimization are the one we actually use in production.
For a higher internal cohesion, `BuildingValidator` does not know anything about optimization, which is taken care of by a `BuildingValidationOptimizer` python class. Two dataclasses are used to connect the two objects
- `BuildingValidationClusterInfo`: describes the cluster-level information, necessary to perform a validation
- `thresholds`: describes the different thresholds used in `BuildingValidator` and optimized in `BuildingValidationOptimizer`.

In Building Validation, the most time-consuming step is the preparation of data, including the clustering of candidate building points and the overlay of vectors of buildings from a public databse: up to several minutes per km² of data. The `BuildingValidationOptimizer` breaks down the Building Validation steps to make sure that data preparation only occurs onces.
The steps are the following:

1. Preparation

    Prepares and saves each point cloud in the specified directory, and extracts all cluster information in a list of `BuildingValidationClusterInfo` objects that is pickled. 
2. Optimization

3. Evaluation

4. Update

## Running the optimization

> Refer to the [installation tutorial](tutorials/install_and_use.md) to set up your environment.



```bash
conda activate lidar_prod

python lidar_prod/run.py \
+task=optimize building_validation.optimization.todo='prepare+optimize+evaluate+update' \
building_validation.optimization.paths.input_las_dir=[path/to/labelled/val/dataset/] \
building_validation.optimization.paths.results_output_dir=[path/to/save/results] 
```
Debug mode: to run on a single file during development, add a `+building_validation.optimization.debug=true` flag to the command line.

Optimized decision threshold will be pickled inside the results directory.

To evaluate the optimized module on a test set, change input las folder, and rerun. You need to specify that no optimization is required using the `todo` params. You also need to give the path to the pickled decision trheshold.

```bash
conda activate lidar_prod
python lidar_prod/run.py +task=optimize building_validation.optimization.todo='prepare+evaluate+update' building_validation.optimization.paths.input_las_dir=[path/to/labelled/test/dataset/] building_validation.optimization.paths.results_output_dir=[path/to/save/results] building_validation.optimization.paths.building_validation_thresholds_pickle=[path/to/optimized_thresholds.pickle]
```



Reference:
- [Deb et al. (2002) - A fast and elitist multiobjective genetic algorithm\: NSGA-II](https://ieeexplore.ieee.org/document/996017)).